{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a91e0d-9f05-4dd6-9776-42ac31e04cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/md1011/Library/Python/3.8/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading: 100%|████████████████████████████| 816k/816k [00:04<00:00, 167kB/s]\n",
      "Downloading: 100%|███████████████████████████| 458k/458k [00:56<00:00, 8.10kB/s]\n",
      "Downloading: 100%|█████████████████████████████| 656/656 [00:00<00:00, 66.8kB/s]\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
      "Downloading: 100%|███████████████████████████| 479M/479M [01:33<00:00, 5.12MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import OpenAIGPTTokenizer, OpenAIGPTModel\n",
    "import torch\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")\n",
    "model = OpenAIGPTModel.from_pretrained(\"openai-gpt\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8bce65-a66b-4a38-823b-c01375b52419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutput(last_hidden_state=tensor([[[ 0.4653,  0.0642,  0.5910,  ...,  0.1177, -0.0021, -1.2262],\n",
       "         [-0.3697, -0.0957,  0.6613,  ..., -0.0344, -0.2164,  0.1205],\n",
       "         [ 0.1700, -0.3252,  0.0407,  ...,  0.1589, -0.8057, -0.2830],\n",
       "         [-0.3669, -0.0448,  0.8061,  ..., -0.0090, -0.0872, -0.5224],\n",
       "         [-0.5047,  0.6522,  0.6932,  ...,  0.0811,  0.6475,  0.3190],\n",
       "         [-0.2972,  0.0591,  1.2333,  ..., -0.7394, -0.2600,  0.0863]]],\n",
       "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dccac17-33be-49b4-a7e4-27240be8c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7648bbae-4843-4305-b862-78b922ffe08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://huggingface.co/docs/transformers/model_doc/openai-gpt\n",
    "https://huggingface.co/openai-gpt\n",
    "'''\n",
    "import torch\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86ca574d-eaa7-4473-8682-edeb7477e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69b175c7-5aea-464a-9140-246b3327bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = GPT2Model.from_pretrained(\"gpt2\")\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864a3001-8700-4391-8454-bd1dd2bc7805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
      "\n",
      "I'm not sure if I'll\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ref: https://huggingface.co/blog/how-to-generate\n",
    "'''\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='pt')\n",
    "\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a05fee-982d-4e4e-9add-20d58178e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "-> how are you?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "how are you?\n",
      "\n",
      "I'm not sure. I'm not sure if I'm going to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "memory = 0\n",
    "history_sentence = []\n",
    "max_length = 20\n",
    "while True:\n",
    "    s = input('->')\n",
    "    print('\\n')\n",
    "    s_ = ', '.join(history_sentence[-memory:]+[s])\n",
    "    input_ids = tokenizer.encode(s_, return_tensors='pt')\n",
    "    greedy_output = model.generate(input_ids, max_length=max_length)\n",
    "    gpt_s = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    print(gpt_s+'\\n')\n",
    "    if s == 'STOP':\n",
    "        break\n",
    "    history_sentence += [s, gpt_s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8d73d85-f515-442f-81c3-bfa9d8425ed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[456]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_sentence = [123,456]\n",
    "history_sentence[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc01520-b4ef-4226-877b-71d8899449d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08182e-2c6f-4dbf-9421-ce804e6706df",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "other ref:\n",
    "https://zhuanlan.zhihu.com/p/590311003\n",
    "https://github.com/tatsu-lab/stanford_alpaca\n",
    "https://github.com/BlinkDL/ChatRWKV\n",
    "https://github.com/togethercomputer/OpenChatKit\n",
    "https://zhuanlan.zhihu.com/p/614354549\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc90d6d-c843-40ff-8da1-5f5629da1988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd155b5f-fa7c-46bd-9a40-f005da650106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f49002-f93e-4979-9881-e7c12d9fb749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
